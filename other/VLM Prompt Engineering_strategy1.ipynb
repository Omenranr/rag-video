{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a983d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 2 is:\n",
    "# 1. Generate 1 global summary of the video by picking frames from whole video and generating global summary.\n",
    "# 2. Divide video into scenes of 10 secondes.\n",
    "# 3. Run over each scene and take 8 frames and then do generation with global context + prompt + frames\n",
    "# 4. Save results in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5da9b0-220f-46c0-9141-6fada80c8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers decord einops timm accelerate flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef32065-1a4c-447f-ba77-2c4dde9c7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import datetime as dt\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from PIL import Image\n",
    "from decord import VideoReader, cpu\n",
    "from transformers import AutoModel, AutoTokenizer, TextIteratorStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3914ce15-3422-48fe-b705-df7ade0b9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "VIDEO_PATH = \"video_foot_highlights.mp4\"   # <— change or pass from argv if you prefer\n",
    "SCENE_SECONDS = 10                  # fixed 10-second chunks as requested\n",
    "GLOBAL_SAMPLE_SEGMENTS = 16         # frames to sample for \"general metadata\"\n",
    "PER_SCENE_SAMPLE_SEGMENTS = 8       # frames to sample for each scene\n",
    "TILE_MAX_NUM = 1                    # number of tiles per frame (keep 1 for speed)\n",
    "INPUT_SIZE = 448\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d765f1fc-12a4-4c8c-809a-06bd3855109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39d0773f92844eda58bc3642746d69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Model init (your settings)\n",
    "# ----------------------------\n",
    "path = 'OpenGVLab/InternVL3_5-8B'\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    load_in_8bit=False,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc832f-e14a-4da9-9cb9-a10de6efc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Prompts (Global + Scene Card for RAG)\n",
    "# ----------------------------\n",
    "GLOBAL_PROMPT = (\n",
    "    \"You are analyzing sampled frames from the WHOLE video. Provide:\\n\"\n",
    "    \"- Video type/genre (e.g., sports/soccer match highlight, vlog, screencast, ad, tutorial, etc.)\\n\"\n",
    "    \"- Global video summary with only IMPORTANT informations.\\n\"\n",
    "    \"- Likely action types present (bulleted)\\n\"\n",
    "    \"- Prominent entities/teams/brands (bulleted)\\n\"\n",
    "    \"- Visual style cues (e.g., broadcast overlay, handheld, studio)\\n\"\n",
    "    \"Return sections: [TYPE], [SUMMARY], [ACTIONS], [ENTITIES], [STYLE].\"\n",
    ")\n",
    "\n",
    "def build_scene_prompt(global_summary_text: str,\n",
    "                       scene_id: int,\n",
    "                       start_s: float,\n",
    "                       end_s: float,\n",
    "                       video_name: str,\n",
    "                       start_tc: str,\n",
    "                       end_tc: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a RAG-friendly SCENE CARD prompt.\n",
    "    The model should return plain text in MARKDOWN format with clear sections and bullets.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "You will receive frames from a ~10-second SCENE in a larger video.\n",
    "Use the GLOBAL CONTEXT below to disambiguate entities/actions when helpful,\n",
    "but do not contradict the visible frames.\n",
    "\n",
    "GLOBAL CONTEXT (model-inferred summary of the whole video):\n",
    "{global_summary_text.strip()}\n",
    "\n",
    "TASK:\n",
    "Describe ONLY this scene and produce a **RAG SCENE CARD** in plain text.\n",
    "The output MUST follow the format below exactly. Keep it factual and concise.\n",
    "\n",
    "FORMAT TO RETURN (plain text, no markdown code fences):\n",
    "RAG SCENE CARD\n",
    "---\n",
    "Meta:\n",
    "- video_name: {video_name}\n",
    "- scene_id: {scene_id}\n",
    "- start_sec: {start_s:.3f}\n",
    "- end_sec: {end_s:.3f}\n",
    "- start_timecode: {start_tc}\n",
    "- end_timecode: {end_tc}\n",
    "\n",
    "Context:\n",
    "- global_type: <from context if relevant, else unknown>\n",
    "- global_summary: <1-2 lines linking this scene to the whole video, or 'unknown'>\n",
    "\n",
    "OnScreenText:\n",
    "- lines:\n",
    "  - <exact OCR line 1>\n",
    "  - <exact OCR line 2>\n",
    "  - ...\n",
    "\n",
    "Description:\n",
    "- dense: <who/what/where, key objects, visual context in 3-5 lines> in chronological order.\n",
    "- actions:\n",
    "  - <verb / short action phrase>\n",
    "  - <...>\n",
    "\n",
    "Entities:\n",
    "- items:\n",
    "  - type: <person/team/logo/brand/location/object/number/other>\n",
    "    name_or_value: <best guess or exact text>\n",
    "    attributes: [<short attrs like jersey #, color, role, number>]\n",
    "  - ...\n",
    "\n",
    "Tags:\n",
    "- scene_tags: [<short keywords like teams, brands, numbers, clothes, location>, ...]\n",
    "\n",
    "Confidence:\n",
    "- overall: <0.0-1.0>\n",
    "- ocr: <0.0-1.0>\n",
    "- entity_detection: <0.0-1.0>\n",
    "\n",
    "NOTES:\n",
    "- For OnScreenText, list ALL elegible text exactly as written (preserve case).\n",
    "- Prefer short bullets and compact phrases for actions/tags/entities.\n",
    "- If unknown or not visible, write 'unknown' or use empty lists [].\n",
    "- Return ONLY the card content in this exact structure (no extra commentary).\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2390d9-102b-41b5-ab74-f6dcfa4c1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Main processing (VERBOSE)\n",
    "# ----------------------------\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def _setup_logger(name: str = \"video_rag\", level: int = logging.INFO) -> logging.Logger:\n",
    "    logger = logging.getLogger(name)\n",
    "    if logger.handlers:\n",
    "        return logger  # already configured\n",
    "    logger.setLevel(level)\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    formatter = logging.Formatter(\n",
    "        fmt=\"%(asctime)s | %(levelname)-7s | %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "LOGGER = _setup_logger()\n",
    "\n",
    "# ----------------------------\n",
    "# Image / Video utilities\n",
    "# ----------------------------\n",
    "def build_transform(input_size):\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1)\n",
    "        if i * j <= max_num and i * j >= min_num\n",
    "    )\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size\n",
    "    )\n",
    "\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def build_transform_and_stack(frames_as_pil, input_size=448, max_num=1):\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    tiles = []\n",
    "    for img in frames_as_pil:\n",
    "        img_tiles = dynamic_preprocess(img, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "        tile_tensor = [transform(tile) for tile in img_tiles]\n",
    "        tile_tensor = torch.stack(tile_tensor)\n",
    "        tiles.append(tile_tensor)\n",
    "    pixel_values = torch.cat(tiles)\n",
    "    return pixel_values\n",
    "\n",
    "def seconds_to_tc(t):\n",
    "    # HH:MM:SS.mmm\n",
    "    hours = int(t // 3600)\n",
    "    minutes = int((t % 3600) // 60)\n",
    "    seconds = t % 60\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:06.3f}\"\n",
    "\n",
    "def get_frame_indices(bound, fps, max_frame, first_idx=0, num_segments=32, frames_per_segment=1):\n",
    "    \"\"\"\n",
    "    Select frame indices evenly across the [start, end] bound.\n",
    "    Instead of just one per segment, allow multiple frames per segment.\n",
    "    \"\"\"\n",
    "    if bound:\n",
    "        start, end = bound[0], bound[1]\n",
    "    else:\n",
    "        start, end = -100000, 100000\n",
    "\n",
    "    start_idx = max(first_idx, round(start * fps))\n",
    "    end_idx = min(round(end * fps), max_frame)\n",
    "    if end_idx <= start_idx:\n",
    "        end_idx = min(start_idx + max(1, int(fps)), max_frame)  # ensure ~1s coverage\n",
    "\n",
    "    seg_size = float(end_idx - start_idx) / num_segments\n",
    "    frame_indices = []\n",
    "\n",
    "    for idx in range(num_segments):\n",
    "        seg_start = start_idx + seg_size * idx\n",
    "        seg_end = start_idx + seg_size * (idx + 1)\n",
    "\n",
    "        if frames_per_segment == 1:\n",
    "            # original behavior (center of segment)\n",
    "            frame_idx = int(seg_start + (seg_size / 2))\n",
    "            frame_indices.append(frame_idx)\n",
    "        else:\n",
    "            # evenly spaced frames inside the segment\n",
    "            for j in range(frames_per_segment):\n",
    "                pos = seg_start + (seg_size * (j + 0.5) / frames_per_segment)\n",
    "                frame_indices.append(int(pos))\n",
    "\n",
    "    return np.clip(frame_indices, start_idx, end_idx)\n",
    "\n",
    "\n",
    "def load_video_pixel_values(video_path, bound=None, input_size=448, max_num=1, num_segments=32):\n",
    "    vr = VideoReader(video_path, ctx=cpu(0), num_threads=1)\n",
    "    max_frame = len(vr) - 1\n",
    "    fps = float(vr.get_avg_fps())\n",
    "    frame_indices = get_frame_indices(bound, fps, max_frame, num_segments=num_segments, frames_per_segment=2)\n",
    "    frames_as_pil = [Image.fromarray(vr[int(idx)].asnumpy()).convert('RGB') for idx in frame_indices]\n",
    "    pixel_values = build_transform_and_stack(frames_as_pil, input_size=input_size, max_num=max_num)\n",
    "    return pixel_values, len(frame_indices), fps, vr[0].shape[1], vr[0].shape[0]  # width, height\n",
    "\n",
    "# ----------------------------\n",
    "# Generation helpers (VERBOSE)\n",
    "# ----------------------------\n",
    "def chat_with_images(pixel_values, question, timeout=30):\n",
    "    \"\"\"\n",
    "    Runs model.chat with streaming and returns the consolidated string.\n",
    "    Logs live output so you can see what the model generates.\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    # Move tensor to GPU/CPU\n",
    "    if USE_CUDA:\n",
    "        pixel_values = pixel_values.to(torch.bfloat16).cuda()\n",
    "        LOGGER.info(f\"chat_with_images | Using CUDA | tensor shape={tuple(pixel_values.shape)}\")\n",
    "    else:\n",
    "        pixel_values = pixel_values.to(torch.bfloat16)\n",
    "        LOGGER.info(f\"chat_with_images | Using CPU | tensor shape={tuple(pixel_values.shape)}\")\n",
    "\n",
    "    LOGGER.info(f\"Prompt length: {len(question)} chars\")\n",
    "    streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True, timeout=timeout)\n",
    "    generation_config = dict(max_new_tokens=1024, do_sample=False, streamer=streamer)\n",
    "\n",
    "    # Run chat in background thread\n",
    "    thread = Thread(target=model.chat, kwargs=dict(\n",
    "        tokenizer=tokenizer, pixel_values=pixel_values, question=question,\n",
    "        history=None, return_history=False, generation_config=generation_config,\n",
    "    ))\n",
    "    thread.start()\n",
    "\n",
    "    chunks = []\n",
    "    LOGGER.info(\">>> Model generation started (streaming)...\")\n",
    "    for new_text in streamer:\n",
    "        if new_text == getattr(model, \"conv_template\", None).sep if hasattr(model, \"conv_template\") else False:\n",
    "            LOGGER.debug(\">>> Separator token reached, stopping stream.\")\n",
    "            break\n",
    "        chunks.append(new_text)\n",
    "        # Print live output as it's generated\n",
    "        sys.stdout.write(new_text)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    result = \"\".join(chunks).strip()\n",
    "    total_time = time.perf_counter() - t0\n",
    "    LOGGER.info(f\"\\n>>> Model generation finished in {total_time:.2f}s \"\n",
    "                f\"({len(result)} chars total).\")\n",
    "    return result\n",
    "\n",
    "def chunk_bounds(duration_sec, chunk_sec):\n",
    "    LOGGER.info(f\"Computing chunk bounds (duration={duration_sec:.3f}s, chunk={chunk_sec}s)\")\n",
    "    n = math.ceil(duration_sec / chunk_sec)\n",
    "    bounds = []\n",
    "    for i in range(n):\n",
    "        start = i * chunk_sec\n",
    "        end = min((i + 1) * chunk_sec, duration_sec)\n",
    "        if end > start:\n",
    "            bounds.append((start, end))\n",
    "    LOGGER.info(f\"Planned {len(bounds)} scene(s) of ~{chunk_sec}s each\")\n",
    "    return bounds\n",
    "\n",
    "def _filesize(path: str) -> str:\n",
    "    try:\n",
    "        sz = os.path.getsize(path)\n",
    "        for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n",
    "            if sz < 1024.0:\n",
    "                return f\"{sz:,.2f} {unit}\"\n",
    "            sz /= 1024.0\n",
    "    except Exception:\n",
    "        return \"n/a\"\n",
    "    return \"n/a\"\n",
    "\n",
    "def process_video(video_path, verbose: bool = True):\n",
    "    t0 = time.perf_counter()\n",
    "    assert os.path.isfile(video_path), f\"Video not found: {video_path}\"\n",
    "    LOGGER.info(f\"Opening video: {video_path}\")\n",
    "\n",
    "    vr = VideoReader(video_path, ctx=cpu(0), num_threads=1)\n",
    "    fps = float(vr.get_avg_fps())\n",
    "    total_frames = len(vr)\n",
    "    duration = total_frames / fps if fps > 0 else 0.0\n",
    "    width = vr[0].shape[1]\n",
    "    height = vr[0].shape[0]\n",
    "    LOGGER.info(f\"Video loaded | fps={fps:.3f}, frames={total_frames}, \"\n",
    "                f\"duration={duration:.3f}s, resolution={width}x{height}\")\n",
    "\n",
    "    # file naming\n",
    "    base = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    stamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_name = f\"{base}_{stamp}.csv\"\n",
    "    meta_name = f\"{base}_{stamp}_metadata.txt\"\n",
    "    LOGGER.info(f\"Output files -> CSV: {csv_name} | Metadata: {meta_name}\")\n",
    "\n",
    "    # Global metadata (model-aided)\n",
    "    LOGGER.info(\"Sampling whole-video frames for global metadata...\")\n",
    "    tg0 = time.perf_counter()\n",
    "    global_px, global_sampled, _, _, _ = load_video_pixel_values(\n",
    "        video_path,\n",
    "        bound=(0, duration),\n",
    "        input_size=INPUT_SIZE,\n",
    "        max_num=TILE_MAX_NUM,\n",
    "        num_segments=GLOBAL_SAMPLE_SEGMENTS\n",
    "    )\n",
    "    LOGGER.info(f\"Global sampling complete | sampled_frames={global_sampled}, \"\n",
    "                f\"segments={GLOBAL_SAMPLE_SEGMENTS}\")\n",
    "    LOGGER.info(\"Generating model-inferred global metadata...\")\n",
    "    global_text = chat_with_images(global_px, GLOBAL_PROMPT)\n",
    "    LOGGER.info(f\"Global metadata generation done in {time.perf_counter() - tg0:.2f}s \"\n",
    "                f\"({len(global_text)} chars)\")\n",
    "\n",
    "    # Per-scene extraction\n",
    "    LOGGER.info(\"Processing scenes (per 10s chunk)...\")\n",
    "    bounds = chunk_bounds(duration, SCENE_SECONDS)\n",
    "    total_scenes = len(bounds)\n",
    "    rows = []\n",
    "\n",
    "    for i, (start_s, end_s) in enumerate(bounds, start=1):\n",
    "        ts_scene_start = time.perf_counter()\n",
    "        pct = (i / total_scenes) * 100 if total_scenes else 100\n",
    "        LOGGER.info(f\"[{i}/{total_scenes}] ({pct:5.1f}%) Scene timecodes \"\n",
    "                    f\"{seconds_to_tc(start_s)} → {seconds_to_tc(end_s)} \"\n",
    "                    f\"({end_s - start_s:.3f}s)\")\n",
    "        try:\n",
    "            # Load frames for the scene\n",
    "            tl0 = time.perf_counter()\n",
    "            px, sampled, fps_local, w, h = load_video_pixel_values(\n",
    "                video_path,\n",
    "                bound=(start_s, end_s),\n",
    "                input_size=INPUT_SIZE,\n",
    "                max_num=TILE_MAX_NUM,\n",
    "                num_segments=PER_SCENE_SAMPLE_SEGMENTS\n",
    "            )\n",
    "            LOGGER.info(f\"  • Frames sampled for scene: {sampled} (segments={PER_SCENE_SAMPLE_SEGMENTS}) \"\n",
    "                        f\"| res={w}x{h} | load_time={time.perf_counter() - tl0:.2f}s\")\n",
    "\n",
    "            # Model generation\n",
    "            tg0 = time.perf_counter()\n",
    "            LOGGER.info(\"  • Generating scene text with model...\")\n",
    "            # NEW: scene prompt includes global summary + strict JSON spec\n",
    "            scene_prompt = build_scene_prompt(\n",
    "                global_summary_text=global_text,\n",
    "                scene_id=i,\n",
    "                start_s=start_s,\n",
    "                end_s=end_s,\n",
    "                video_name=base,\n",
    "                start_tc=seconds_to_tc(start_s),\n",
    "                end_tc=seconds_to_tc(end_s)\n",
    "            )\n",
    "            scene_text = chat_with_images(px, scene_prompt)\n",
    "            LOGGER.info(f\"  • Generation done in {time.perf_counter() - tg0:.2f}s \"\n",
    "                        f\"({len(scene_text)} chars)\")\n",
    "\n",
    "            row = {\n",
    "                \"video_name\": base,\n",
    "                \"video_path\": os.path.abspath(video_path),\n",
    "                \"scene_id\": i,\n",
    "                \"start_sec\": round(float(start_s), 3),\n",
    "                \"end_sec\": round(float(end_s), 3),\n",
    "                \"start_timecode\": seconds_to_tc(start_s),\n",
    "                \"end_timecode\": seconds_to_tc(end_s),\n",
    "                \"scene_duration_sec\": round(float(end_s - start_s), 3),\n",
    "                \"fps\": fps_local,\n",
    "                \"width\": w,\n",
    "                \"height\": h,\n",
    "                \"sampled_frames_for_scene\": sampled,\n",
    "                \"generated_text\": scene_text\n",
    "            }\n",
    "            rows.append(row)\n",
    "            LOGGER.info(f\"  • Scene {i} completed in {time.perf_counter() - ts_scene_start:.2f}s\")\n",
    "\n",
    "        except Exception as e:\n",
    "            LOGGER.exception(f\"  × Scene {i} failed due to error: {e}. Continuing with next scene.\")\n",
    "            # still record a stub row to keep alignment of scene ids\n",
    "            rows.append({\n",
    "                \"video_name\": base,\n",
    "                \"video_path\": os.path.abspath(video_path),\n",
    "                \"scene_id\": i,\n",
    "                \"start_sec\": round(float(start_s), 3),\n",
    "                \"end_sec\": round(float(end_s), 3),\n",
    "                \"start_timecode\": seconds_to_tc(start_s),\n",
    "                \"end_timecode\": seconds_to_tc(end_s),\n",
    "                \"scene_duration_sec\": round(float(end_s - start_s), 3),\n",
    "                \"fps\": fps, \"width\": width, \"height\": height,\n",
    "                \"sampled_frames_for_scene\": 0,\n",
    "                \"generated_text\": f\"[ERROR] {e}\"\n",
    "            })\n",
    "\n",
    "    # Write CSV\n",
    "    LOGGER.info(\"Writing CSV...\")\n",
    "    tcsv0 = time.perf_counter()\n",
    "    fieldnames = list(rows[0].keys()) if rows else [\n",
    "        \"video_name\",\"video_path\",\"scene_id\",\"start_sec\",\"end_sec\",\n",
    "        \"start_timecode\",\"end_timecode\",\"scene_duration_sec\",\"fps\",\"width\",\"height\",\n",
    "        \"sampled_frames_for_scene\",\"generated_text\"\n",
    "    ]\n",
    "    with open(csv_name, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "    LOGGER.info(f\"CSV saved to {csv_name} ({_filesize(csv_name)}) in {time.perf_counter() - tcsv0:.2f}s\")\n",
    "\n",
    "    # Write general metadata text\n",
    "    LOGGER.info(\"Writing general metadata text file...\")\n",
    "    tmeta0 = time.perf_counter()\n",
    "    technical_meta = {\n",
    "        \"file_name\": os.path.basename(video_path),\n",
    "        \"abs_path\": os.path.abspath(video_path),\n",
    "        \"created_at\": stamp,\n",
    "        \"video_length_sec\": round(duration, 3),\n",
    "        \"fps\": fps,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"num_scenes_10s\": len(bounds),\n",
    "        \"scene_seconds\": SCENE_SECONDS\n",
    "    }\n",
    "    meta_header = [\n",
    "        \"# GENERAL VIDEO METADATA\",\n",
    "        \"\",\n",
    "        \"## Technical\",\n",
    "        json.dumps(technical_meta, indent=2),\n",
    "        \"\",\n",
    "        \"## Model-Inferred (Global Sampling)\",\n",
    "        global_text.strip(),\n",
    "        \"\"\n",
    "    ]\n",
    "    with open(meta_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(meta_header))\n",
    "    LOGGER.info(f\"Metadata saved to {meta_name} ({_filesize(meta_name)}) in {time.perf_counter() - tmeta0:.2f}s\")\n",
    "\n",
    "    total_time = time.perf_counter() - t0\n",
    "    LOGGER.info(f\"Done in {total_time:.2f}s | CSV: {csv_name} | Metadata: {meta_name}\")\n",
    "    return csv_name, meta_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88c681-479d-4247-82ba-b659005d2daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-12 17:03:47 | INFO    | Opening video: video_foot_highlights.mp4\n",
      "2025-09-12 17:03:47 | INFO    | Video loaded | fps=25.000, frames=22684, duration=907.360s, resolution=640x360\n",
      "2025-09-12 17:03:47 | INFO    | Output files -> CSV: video_foot_highlights_20250912_170347.csv | Metadata: video_foot_highlights_20250912_170347_metadata.txt\n",
      "2025-09-12 17:03:47 | INFO    | Sampling whole-video frames for global metadata...\n",
      "2025-09-12 17:03:49 | INFO    | Global sampling complete | sampled_frames=32, segments=16\n",
      "2025-09-12 17:03:49 | INFO    | Generating model-inferred global metadata...\n",
      "2025-09-12 17:03:49 | INFO    | chat_with_images | Using CUDA | tensor shape=(32, 3, 448, 448)\n",
      "2025-09-12 17:03:49 | INFO    | Prompt length: 413 chars\n",
      "2025-09-12 17:03:49 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TYPE]\n",
      "Soccer match highlight\n",
      "\n",
      "[SUMMARY]\n",
      "The video captures key moments from a soccer match between two teams, showing the progression of the game, goals scored, and reactions from players and fans.\n",
      "\n",
      "[ ACTIONS ]\n",
      "- Players running and dribbling the ball\n",
      "- Goal attempts and shots on goal\n",
      "- Celebrations after scoring\n",
      "- Defensive actions and tackles\n",
      "- Audience cheering and reactions\n",
      "\n",
      "[ ENTITIES ]\n",
      "- Team in blue and red uniforms\n",
      "- Team in white uniforms\n",
      "- Referee in yellow\n",
      "- Soccer ball\n",
      "- Stadium and audience\n",
      "- Broadcast overlays showing scores and time\n",
      "\n",
      "[ STYLE ]\n",
      "- Broadcast overlay with score and time information\n",
      "- Professional sports broadcast quality\n",
      "- Dynamic camera angles capturing both gameplay and audience reactions2025-09-12 17:03:56 | INFO    | \n",
      ">>> Model generation finished in 7.52s (728 chars total).\n",
      "2025-09-12 17:03:56 | INFO    | Global metadata generation done in 8.89s (728 chars)\n",
      "2025-09-12 17:03:56 | INFO    | Processing scenes (per 10s chunk)...\n",
      "2025-09-12 17:03:56 | INFO    | Computing chunk bounds (duration=907.360s, chunk=10s)\n",
      "2025-09-12 17:03:56 | INFO    | Planned 91 scene(s) of ~10s each\n",
      "2025-09-12 17:03:56 | INFO    | [1/91] (  1.1%) Scene timecodes 00:00:00.000 → 00:00:10.000 (10.000s)\n",
      "2025-09-12 17:03:56 | INFO    |   • Frames sampled for scene: 16 (segments=8) | res=640x360 | load_time=0.25s\n",
      "2025-09-12 17:03:56 | INFO    |   • Generating scene text with model...\n",
      "2025-09-12 17:03:56 | INFO    | chat_with_images | Using CUDA | tensor shape=(16, 3, 448, 448)\n",
      "2025-09-12 17:03:56 | INFO    | Prompt length: 2565 chars\n",
      "2025-09-12 17:03:56 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG SCENE CARD\n",
      "---\n",
      "Meta:\n",
      "- video_name: video_foot_highlights\n",
      "- scene_id: 1\n",
      "- start_sec: 0.000\n",
      "- end_sec: 10.000\n",
      "- start_timecode: 00:00:00.000\n",
      "- end_timecode: 00:00:10.000\n",
      "\n",
      "Context:\n",
      "- global_type: Soccer match highlight\n",
      "- global_summary: Captures key moments from a soccer match, showing gameplay and audience reactions.\n",
      "\n",
      "OnScreenText:\n",
      "- lines:\n",
      "  - VIVEZ LE FOOTBALL SUR DAZN SPORTS\n",
      "  - LIGUE: 1-2 LIGUE: 2\n",
      "  - LIGUE: 1 LIGUE: 2\n",
      "  - LIGUE: 1 LIGUE: 2\n",
      "  - LIGUE: 1 LIGUE: 2\n",
      "  - LIGUE: 1 LIGUE: 2\n",
      "  - LIGUE: 1 LIGUE: 2\n",
      "  - DAZN SPORTS\n",
      "  - 15€/MOIS sans engagement\n",
      "\n",
      "Description:\n",
      "- dense: Soccer match in progress with players in white and blue/red uniforms on the field. Referee in yellow is adjusting his earpiece. Stadium filled with spectators.\n",
      "- actions:\n",
      "  - Players positioning on the field\n",
      "  - Referee adjusting earpiece\n",
      "\n",
      "Entities:\n",
      "- items:\n",
      "  - type: person\n",
      "    name_or_value: Referee\n",
      "    attributes: [role: referee, uniform: yellow]\n",
      "  - type: team\n",
      "    name_or_value: Team in white uniforms\n",
      "    attributes: [jersey color: white]\n",
      "  - type: team\n",
      "    name_or_value: Team in blue and red uniforms\n",
      "    attributes: [jersey color: blue/red]\n",
      "\n",
      "Tags:\n",
      "- scene_tags: [soccer, teams, referee, stadium, broadcast]\n",
      "\n",
      "Shot:\n",
      "- camera_motion: [static]\n",
      "- camera_angle: [wide]\n",
      "- cuts_or_transitions: []\n",
      "\n",
      "Confidence:\n",
      "- overall: 0.9\n",
      "- ocr: 0.95\n",
      "- entity_detection: 0.85\n",
      "\n",
      "NOTES:\n",
      "- For OnScreenText, all legible text from the broadcast overlay is included.\n",
      "- The scene captures the setup before active gameplay begins.2025-09-12 17:04:14 | INFO    | \n",
      ">>> Model generation finished in 17.89s (1496 chars total).\n",
      "2025-09-12 17:04:14 | INFO    |   • Generation done in 17.89s (1496 chars)\n",
      "2025-09-12 17:04:14 | INFO    |   • Scene 1 completed in 18.14s\n",
      "2025-09-12 17:04:14 | INFO    | [2/91] (  2.2%) Scene timecodes 00:00:10.000 → 00:00:20.000 (10.000s)\n",
      "2025-09-12 17:04:15 | INFO    |   • Frames sampled for scene: 16 (segments=8) | res=640x360 | load_time=0.28s\n",
      "2025-09-12 17:04:15 | INFO    |   • Generating scene text with model...\n",
      "2025-09-12 17:04:15 | INFO    | chat_with_images | Using CUDA | tensor shape=(16, 3, 448, 448)\n",
      "2025-09-12 17:04:15 | INFO    | Prompt length: 2566 chars\n",
      "2025-09-12 17:04:15 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG SCENE CARD\n",
      "---\n",
      "Meta:\n",
      "- video_name: video_foot_highlights\n",
      "- scene_id: 2\n",
      "- start_sec: 10.000\n",
      "- end_sec: 20.000\n",
      "- start_timecode: 00:00:10.000\n",
      "- end_timecode: 00:00:20.000\n",
      "\n",
      "Context:\n",
      "- global_type: Soccer match highlight\n",
      "- global_summary: This scene captures a moment from a soccer match, showing players on the field and reactions from the sidelines.\n",
      "\n",
      "OnScreenText:\n",
      "- lines:\n",
      "  - DIGNITY\n",
      "  - DON SPORTS\n",
      "\n",
      "Description:\n",
      "- dense: Players in white and blue uniforms are on the field, with a referee in yellow nearby. Coaches and staff are seen on the sidelines, some standing and others seated.\n",
      "- actions:\n",
      "  - Players walking on the field\n",
      "  - Coaches conversing and observing the game\n",
      "\n",
      "Entities:\n",
      "- items:\n",
      "  - type: Person/Team\n",
      "    name_or_value: Team in white uniforms\n",
      "    attributes: [jersey color: white]\n",
      "  - type: Person/Team\n",
      "    name_or_value: Team in blue uniforms\n",
      "    attributes: [jersey color: blue]\n",
      "  - type: Person/Role\n",
      "    name_or_value: Referee\n",
      "    attributes: [uniform: yellow]\n",
      "  - type: Person/Role\n",
      "    name_or_value: Coaches and staff\n",
      "    attributes: [clothing: casual, navy]\n",
      "\n",
      "Tags:\n",
      "- scene_tags: [teams, referee, coaches, sidelines, soccer match]\n",
      "\n",
      "Shot:\n",
      "- camera_motion: [static]\n",
      "- camera_angle: [wide]\n",
      "- cuts_or_transitions: []\n",
      "\n",
      "Confidence:\n",
      "- overall: 0.9\n",
      "- ocr: 0.95\n",
      "- entity_detection: 0.85\n",
      "\n",
      "NOTES:\n",
      "- For OnScreenText, all legible text has been listed exactly as written.\n",
      "- Actions and entities are described based on visible elements in the scene.2025-09-12 17:04:30 | INFO    | \n",
      ">>> Model generation finished in 15.59s (1461 chars total).\n",
      "2025-09-12 17:04:30 | INFO    |   • Generation done in 15.59s (1461 chars)\n",
      "2025-09-12 17:04:30 | INFO    |   • Scene 2 completed in 15.87s\n",
      "2025-09-12 17:04:30 | INFO    | [3/91] (  3.3%) Scene timecodes 00:00:20.000 → 00:00:30.000 (10.000s)\n",
      "2025-09-12 17:04:31 | INFO    |   • Frames sampled for scene: 16 (segments=8) | res=640x360 | load_time=0.30s\n",
      "2025-09-12 17:04:31 | INFO    |   • Generating scene text with model...\n",
      "2025-09-12 17:04:31 | INFO    | chat_with_images | Using CUDA | tensor shape=(16, 3, 448, 448)\n",
      "2025-09-12 17:04:31 | INFO    | Prompt length: 2566 chars\n",
      "2025-09-12 17:04:31 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG SCENE CARD\n",
      "---\n",
      "Meta:\n",
      "- video_name: video_foot_highlights\n",
      "- scene_id: 3\n",
      "- start_sec: 20.000\n",
      "- end_sec: 30.000\n",
      "- start_timecode: 00:00:20.000\n",
      "- end_timecode: 00:00:30.000\n",
      "\n",
      "Context:\n",
      "- global_type: Soccer match highlight\n",
      "- global_summary: Captures key moments from a soccer match, including player actions and audience reactions.\n",
      "\n",
      "OnScreenText:\n",
      "- lines:\n",
      "  - Lamine\n",
      "  - Confinado de la曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心曜心2025-09-12 17:05:12 | INFO    | \n",
      ">>> Model generation finished in 41.22s (1272 chars total).\n",
      "2025-09-12 17:05:12 | INFO    |   • Generation done in 41.22s (1272 chars)\n",
      "2025-09-12 17:05:12 | INFO    |   • Scene 3 completed in 41.52s\n",
      "2025-09-12 17:05:12 | INFO    | [4/91] (  4.4%) Scene timecodes 00:00:30.000 → 00:00:40.000 (10.000s)\n",
      "2025-09-12 17:05:12 | INFO    |   • Frames sampled for scene: 16 (segments=8) | res=640x360 | load_time=0.33s\n",
      "2025-09-12 17:05:12 | INFO    |   • Generating scene text with model...\n",
      "2025-09-12 17:05:12 | INFO    | chat_with_images | Using CUDA | tensor shape=(16, 3, 448, 448)\n",
      "2025-09-12 17:05:12 | INFO    | Prompt length: 2566 chars\n",
      "2025-09-12 17:05:12 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG SCENE CARD\n",
      "---\n",
      "Meta:\n",
      "- video_name: video_foot_highlights\n",
      "- scene_id: 4\n",
      "- start_sec: 30.000\n",
      "- end_sec: 40.000\n",
      "- start_timecode: 00:00:30.000\n",
      "- end_timecode: 00:00:40.000\n",
      "\n",
      "Context:\n",
      "- global_type: Soccer match highlight\n",
      "- global_summary: This scene captures gameplay from a soccer match, showing players in action and the ongoing score.\n",
      "\n",
      "OnScreenText:\n",
      "- lines:\n",
      "  - RAVI VALLECANO 0 - 0 FC BARCELONA\n",
      "  - LALIGA\n",
      "\n",
      "Description:\n",
      "- dense: Players in blue and red uniforms are attacking the goal defended by players in white uniforms. The stadium is filled with spectators.\n",
      "- actions:\n",
      "  - Players running and dribbling the ball\n",
      "  - Goal attempts and defensive actions\n",
      "\n",
      "Entities:\n",
      "- items:\n",
      "  - type: Team\n",
      "    name_or_value: RAVI VALLECANO\n",
      "    attributes: [blue and red uniforms]\n",
      "  - type: Team\n",
      "    name_or_value: FC BARCELONA\n",
      "    attributes: [white uniforms]\n",
      "  - type: Referee\n",
      "    name_or_value: unknown\n",
      "    attributes: [yellow uniform]\n",
      "  - type: Object\n",
      "    name_or_value: Soccer ball\n",
      "    attributes: []\n",
      "  - type: Location\n",
      "    name_or_value: Stadium\n",
      "    attributes: []\n",
      "\n",
      "Tags:\n",
      "- scene_tags: [soccer, teams, stadium, match]\n",
      "\n",
      "Shot:\n",
      "- camera_motion: [static]\n",
      "- camera_angle: [wide]\n",
      "- cuts_or_transitions: []\n",
      "\n",
      "Confidence:\n",
      "- overall: 0.9\n",
      "- ocr: 0.95\n",
      "- entity_detection: 0.85\n",
      "\n",
      "NOTES:\n",
      "- For OnScreenText, all legible text is listed exactly as written.\n",
      "- Actions and entities are described based on visible frames and global context.2025-09-12 17:05:27 | INFO    | \n",
      ">>> Model generation finished in 15.26s (1416 chars total).\n",
      "2025-09-12 17:05:27 | INFO    |   • Generation done in 15.26s (1416 chars)\n",
      "2025-09-12 17:05:27 | INFO    |   • Scene 4 completed in 15.59s\n",
      "2025-09-12 17:05:27 | INFO    | [5/91] (  5.5%) Scene timecodes 00:00:40.000 → 00:00:50.000 (10.000s)\n",
      "2025-09-12 17:05:28 | INFO    |   • Frames sampled for scene: 16 (segments=8) | res=640x360 | load_time=0.35s\n",
      "2025-09-12 17:05:28 | INFO    |   • Generating scene text with model...\n",
      "2025-09-12 17:05:28 | INFO    | chat_with_images | Using CUDA | tensor shape=(16, 3, 448, 448)\n",
      "2025-09-12 17:05:28 | INFO    | Prompt length: 2566 chars\n",
      "2025-09-12 17:05:28 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG SCENE CARD\n",
      "---\n",
      "Meta:\n",
      "- video_name: video_foot_highlights\n",
      "- scene_id: 5\n",
      "- start_sec: 40.000\n",
      "- end_sec: 50.000\n",
      "- start_timecode: 00:00:40.000\n",
      "- end_timecode: 00:00:50.000\n",
      "\n",
      "Context:\n",
      "- global_type: Soccer match highlight\n",
      "- global_summary: This scene captures a moment from a soccer match, showing the progression of play and defensive actions.\n",
      "\n",
      "OnScreenText:\n",
      "- lines:\n",
      "  - RAYO 0 - 0 LA LIGA\n",
      "  - 03:21 - 0\n",
      "  - BETLAND\n",
      "  - #RayBarça\n",
      "\n",
      "Description:\n",
      "- dense: The team in white is attacking near the goal, while the team in blue and red defends. The goalkeeper is positioned near the goalpost.\n",
      "- actions:\n",
      "  - Players running and positioning\n",
      "  - Defensive block by the team in blue and red\n",
      "  - Goalkeeper preparing for a potential save\n",
      "\n",
      "Entities:\n",
      "- items:\n",
      "  - type: Team\n",
      "    name_or_value: Team in white uniforms\n",
      "    attributes: [color: white]\n",
      "  - type: Team\n",
      "    name_or_value: Team in blue and red uniforms\n",
      "    attributes: [color: blue and red]\n",
      "  - type: Person\n",
      "    name_or_value: Referee\n",
      "    attributes: [uniform: yellow]\n",
      "  - type: Object\n",
      "    name_or_value: Soccer ball\n",
      "    attributes: []\n",
      "  - type: Brand\n",
      "    name_or_value: BETLAND\n",
      "    attributes: []\n",
      "\n",
      "Tags:\n",
      "- scene_tags: [soccer, teams, stadium, BETLAND, defense]\n",
      "\n",
      "Shot:\n",
      "- camera_motion: [static]\n",
      "- camera_angle: [wide]\n",
      "- cuts_or_transitions: []\n",
      "\n",
      "Confidence:\n",
      "- overall: 0.9\n",
      "- ocr: 0.95\n",
      "- entity_detection: 0.85\n",
      "\n",
      "NOTES:\n",
      "- For OnScreenText, all legible text is listed exactly as written.\n",
      "- Actions and entities are described based on visible frames and global context.2025-09-12 17:05:44 | INFO    | \n",
      ">>> Model generation finished in 16.50s (1512 chars total).\n",
      "2025-09-12 17:05:44 | INFO    |   • Generation done in 16.50s (1512 chars)\n",
      "2025-09-12 17:05:44 | INFO    |   • Scene 5 completed in 16.85s\n",
      "2025-09-12 17:05:44 | INFO    | [6/91] (  6.6%) Scene timecodes 00:00:50.000 → 00:01:00.000 (10.000s)\n",
      "2025-09-12 17:05:45 | INFO    |   • Frames sampled for scene: 16 (segments=8) | res=640x360 | load_time=0.34s\n",
      "2025-09-12 17:05:45 | INFO    |   • Generating scene text with model...\n",
      "2025-09-12 17:05:45 | INFO    | chat_with_images | Using CUDA | tensor shape=(16, 3, 448, 448)\n",
      "2025-09-12 17:05:45 | INFO    | Prompt length: 2566 chars\n",
      "2025-09-12 17:05:45 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG SCENE CARD\n",
      "---\n",
      "Meta:\n",
      "- video_name: video_foot_highlights\n",
      "- scene_id: 6\n",
      "- start_sec: 50.000\n",
      "- end_sec: 60.000\n",
      "- start_timecode: 00:00:50.000\n",
      "- end_timecode: 00:01:00.000\n",
      "\n",
      "Context:\n",
      "- global_type: Soccer match highlight\n",
      "- global_summary: Captures key moments from a soccer match, focusing on gameplay and audience reactions.\n",
      "\n",
      "OnScreenText:\n",
      "- lines:\n",
      "  - BAR 0\n",
      "  - RMA 0\n",
      "  - 03:53: 0\n",
      "\n",
      "Description:\n",
      "- dense: A player in a blue and red uniform dribbles the ball near the opponent's goal, with the goalkeeper in yellow preparing to defend. The stadium is filled with spectators.\n",
      "- actions:\n",
      "  - Dribbling\n",
      "  - Goal attempt\n",
      "\n",
      "Entities:\n",
      "- items:\n",
      "  - type: Team\n",
      "    name_or_value: Team in blue and red uniforms\n",
      "    attributes: [blue and red jerseys]\n",
      "  - type: Team\n",
      "    name_or_value: Team in white uniforms\n",
      "    attributes: [white jerseys]\n",
      "  - type: Person\n",
      "    name_or_value: Goalkeeper\n",
      "    attributes: [yellow jersey, gloves]\n",
      "  - type: Object\n",
      "    name_or_value: Soccer ball\n",
      "    attributes: []\n",
      "  - type: Location\n",
      "    name_or_value: Stadium\n",
      "    attributes: []\n",
      "\n",
      "Tags:\n",
      "- scene_tags: [soccer, teams, goalkeeper, stadium, gameplay]\n",
      "\n",
      "Shot:\n",
      "- camera_motion: [static]\n",
      "- camera_angle: [wide]\n",
      "- cuts_or_transitions: []\n",
      "\n",
      "Confidence:\n",
      "- overall: 0.9\n",
      "- ocr: 0.95\n",
      "- entity_detection: 0.85\n",
      "\n",
      "NOTES:\n",
      "- For OnScreenText, all legible text is listed exactly as written.\n",
      "- Actions and tags are concise and reflect the visible scene.\n",
      "2025-09-12 17:06:00 | INFO    | \n",
      ">>> Model generation finished in 15.36s (1399 chars total).\n",
      "2025-09-12 17:06:00 | INFO    |   • Generation done in 15.36s (1399 chars)\n",
      "2025-09-12 17:06:00 | INFO    |   • Scene 6 completed in 15.71s\n",
      "2025-09-12 17:06:00 | INFO    | [7/91] (  7.7%) Scene timecodes 00:01:00.000 → 00:01:10.000 (10.000s)\n",
      "2025-09-12 17:06:00 | INFO    |   • Frames sampled for scene: 16 (segments=8) | res=640x360 | load_time=0.33s\n",
      "2025-09-12 17:06:00 | INFO    |   • Generating scene text with model...\n",
      "2025-09-12 17:06:00 | INFO    | chat_with_images | Using CUDA | tensor shape=(16, 3, 448, 448)\n",
      "2025-09-12 17:06:00 | INFO    | Prompt length: 2566 chars\n",
      "2025-09-12 17:06:00 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG SCENE CARD\n",
      "---\n",
      "Meta:\n",
      "- video_name: video_foot_highlights\n",
      "- scene_id: 7\n",
      "- start_sec: 60.000\n",
      "- end_sec: 70.000\n",
      "- start_timecode: 00:01:00.000\n",
      "- end_timecode: 00:01:10.000\n",
      "\n",
      "Context:\n",
      "- global_type: Soccer match highlight\n",
      "- global_summary: Captures key moments from a soccer match, showing gameplay and audience reactions.\n",
      "\n",
      "OnScreenText:\n",
      "- lines:\n",
      "  - 05:39 0\n",
      "  - 05:40 0\n",
      "  - 05:41 0\n",
      "  - 05:42 0\n",
      "  - 05:43 0\n",
      "  - 05:44 0\n",
      "  - 05:45 0\n",
      "  - 05:46 0\n",
      "  - 05:47 0\n",
      "  - 05:48 0\n",
      "  - betway\n",
      "  - CONMEBOL\n",
      "  - #RayBarça\n",
      "\n",
      "Description:\n",
      "- dense: Soccer players in blue and red uniforms are on the field, with a player in white raising his arms. The stadium is filled with spectators.\n",
      "- actions:\n",
      "  - Players running and dribbling the ball\n",
      "  - Player in white raising arms\n",
      "\n",
      "Entities:\n",
      "- items:\n",
      "  - type: person\n",
      "    name_or_value: unknown\n",
      "    attributes: [blue and red uniform]\n",
      "  - type: person\n",
      "    name_or_value: unknown\n",
      "    attributes: [white uniform]\n",
      "  - type: object\n",
      "    name_or_value: soccer ball\n",
      "    attributes: []\n",
      "  - type: location\n",
      "    name_or_value: stadium\n",
      "    attributes: []\n",
      "  - type: text\n",
      "    name_or_value: betway\n",
      "    attributes: [advertisement]\n",
      "  - type: text\n",
      "    name_or_value: CONMEBOL\n",
      "    attributes: [advertisement]\n",
      "\n",
      "Tags:\n",
      "- scene_tags: [soccer, teams, stadium, advertisement, players]\n",
      "\n",
      "Shot:\n",
      "- camera_motion: [static]\n",
      "- camera_angle: [wide]\n",
      "- cuts_or_transitions: []\n",
      "\n",
      "Confidence:\n",
      "- overall: 0.9\n",
      "- ocr: 0.95\n",
      "- entity_detection: 0.85\n",
      "\n",
      "NOTES:\n",
      "- For OnScreenText, all legible text is listed exactly as written.\n",
      "- Actions and tags are concise and reflect the visible scene.2025-09-12 17:06:20 | INFO    | \n",
      ">>> Model generation finished in 19.30s (1564 chars total).\n",
      "2025-09-12 17:06:20 | INFO    |   • Generation done in 19.30s (1564 chars)\n",
      "2025-09-12 17:06:20 | INFO    |   • Scene 7 completed in 19.63s\n",
      "2025-09-12 17:06:20 | INFO    | [8/91] (  8.8%) Scene timecodes 00:01:10.000 → 00:01:20.000 (10.000s)\n",
      "2025-09-12 17:06:20 | INFO    |   • Frames sampled for scene: 16 (segments=8) | res=640x360 | load_time=0.29s\n",
      "2025-09-12 17:06:20 | INFO    |   • Generating scene text with model...\n",
      "2025-09-12 17:06:20 | INFO    | chat_with_images | Using CUDA | tensor shape=(16, 3, 448, 448)\n",
      "2025-09-12 17:06:20 | INFO    | Prompt length: 2566 chars\n",
      "2025-09-12 17:06:20 | INFO    | >>> Model generation started (streaming)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG SCENE CARD\n",
      "---\n",
      "Meta:\n",
      "- video_name: video_foot_highlights\n",
      "- scene_id: 8\n",
      "- start_sec: 70.000\n",
      "- end_sec: 80.000\n",
      "- start_timecode: "
     ]
    }
   ],
   "source": [
    "process_video(VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af48ff1-37e7-4490-abc7-7540a9363907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
